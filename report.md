清华大学软件学院本科生毕业设计开题报告

项目标题 (Project Title): 面向数据中心AI的可扩展数据集管理系统设计与实现 (Design and Implementation of a Scalable Dataset Management System for Data-Centric AI) 学生姓名 (Student Name): 杨泽远 (Yang Zeyuan) 所在院系 (Department): 软件学院 (School of Software)


--------------------------------------------------------------------------------


1. 引言 (Introduction)

随着人工智能领域的发展进入以数据为核心驱动的时代，系统化、工程化的数据管理已成为提升模型性能和研发效率的关键。传统的“以模型为中心”的方法论逐渐暴露出其局限性，而“以数据为中心”的理念则将高质量、可迭代的数据视为AI系统成功的基石。本报告旨在详细阐述一个专为数据中心AI（Data-Centric AI, DCAI）工作流程设计的数据集管理系统的研究背景、核心挑战、设计目标及实施计划。该系统致力于解决当前AI开发流程中普遍存在的数据版本控制混乱、数据质量参差不齐以及协作效率低下等关键问题，为DCAI的工程实践提供一个坚实、高效的基础设施。

1.1 研究背景 (Research Background)

近年来，人工智能领域正在经历一次深刻的范式转变——从传统的“以模型为中心”（Model-Centric）转向“以数据为中心”（Data-Centric AI, DCAI）。模型中心AI的核心思想是，在给定一个固定的高质量数据集的前提下，通过不断优化模型类型、网络架构和超参数来提升系统性能。然而，众多研究与实践表明，在许多应用场景下，单纯优化模型的策略所带来的性能提升已趋于“平台期”（plateaued）。

与此相对，DCAI是一种整体性方法，涵盖了从数据收集、标注、准备到增强的整个训练数据开发生命周期。其核心理念是将数据本身视为系统工程的核心变量，通过系统化地改进数据质量、扩充数据多样性以及优化数据标注流程，从而实现AI系统性能的显著提升。在DCAI时代，数据质量的可靠性、数据集版本的可追溯性以及数据迭代的效率，已成为决定AI项目成败的关键因素。这种范式转变为高效、专业的数据管理工具带来了迫切的市场需求，也为本项目的研究提供了清晰的时代背景。

1.2 问题陈述与研究动机 (Problem Statement and Motivation)

识别并解决当前AI数据管理流程中的具体问题，对于DCAI理念的成功落地和企业AI能力的规模化发展至关重要。目前，许多AI团队依然依赖于碎片化的工具链，如传统文件系统、简单的对象存储和分散的脚本，这些工具无法满足现代AI工作流程对数据管理的复杂需求。这种工具链的不足直接制约了研发效率和模型质量的上限。

综合分析当前AI数据管理的实践，我们提炼出以下四大核心挑战：

* 版本控制混乱 (Versioning Chaos): 许多团队缺乏对数据集的系统化版本控制机制。开发者常常依赖于手动的文件命名约定（如 data-v1, data-v2）来追踪变更，这不仅容易出错，也使得实验的可复现性大打折扣，严重影响了团队协作效率。
* 数据质量瓶颈 (Data Quality Bottleneck): 数据质量是模型性能的决定性因素。在实际项目中，数据往往存在标签噪声、覆盖范围不完整或有偏见、以及相关文档缺失等问题。缺乏有效的数据验证、清洗和分析工具，导致低质量数据成为限制模型性能上限的关键瓶颈。
* 协作与共享障碍 (Collaboration and Sharing Barriers): 随着AI项目规模的扩大，多团队协作成为常态。然而，现有解决方案难以支持不同团队在自定义数据管道上进行高效协作，数据的发现、共享和复用存在巨大障碍，导致重复性的数据处理工作。
* 工具链碎片化 (Toolchain Fragmentation): AI开发者使用的工具链往往是割裂的。数据存储在对象存储中，元数据可能散落在不同的数据库或文件中，而版本信息则依赖于Git等代码管理工具。这种碎片化的状态导致数据溯源、元数据管理和复杂查询变得异常困难。

开发一个集版本控制、元数据管理、质量监控和高效协作为一体的、专为DCAI工作流程设计的管理系统，是解决上述挑战的有效途径。

1.3 项目目标与意义 (Project Objectives and Significance)

为应对上述挑战，本毕业设计旨在达成以下主要目标：

1. 设计与实现一个数据集管理系统 (DMS): 构建一个功能完备、稳定可靠的后台系统，作为DCAI工作流程的数据基础设施。
2. 支持核心DCAI工作流: 系统必须支持精细化的数据版本控制、丰富的结构化元数据管理，并能通过API与机器学习训练管道无缝集成。
3. 验证系统架构的可行性: 通过原型系统的实现与测试，验证基于“湖仓一体”（Lakehouse）架构在处理AI数据集方面的可扩展性与高效性。

本项目的学术与实践意义在于，它为DCAI的工程化落地提供了一个具体的、可行的基础设施解决方案。通过该系统，AI团队能够显著提升研发的效率、实验的可复现性以及跨团队的协作水平，从而将更多精力投入到数据本身的优化上，最终构建出性能更优、更可靠的AI应用。本项目为数据中心AI时代的工程实践提供了一个坚实的基础。

2. 文献综述与相关工作 (Literature Review and Related Work)

为了明确本项目的技术定位和创新价值，本章节将对当前市场上主流的数据管理与版本控制工具进行分析。通过评估这些现有解决方案在满足内部DCAI工作流程需求方面的优势与不足，我们可以清晰地识别出当前市场的技术差距，从而为本项目的设计提供依据。

平台 (Platform)	核心优势 (Core Strengths)	局限性分析 (Limitations for Internal DCAI Workflows)
Hugging Face	领先的模型和数据集社区中心，极大地促进了NLP和计算机视觉领域的资源共享与发现，拥有庞大的预训练模型和公开数据集库。	主要定位于公开资源的托管与分享，而非为企业内部的私有数据工程、数据治理和自定义数据处理管道提供解决方案。
DVC	与Git工作流深度集成，对开发者友好，通过将数据指针存入Git来管理大规模文件，适合本地开发环境和代码驱动的数据版本管理。	在处理超大规模、结构化数据集时面临挑战，其去中心化的设计使得集中式的元数据管理、查询和权限控制变得复杂。
Graviti	提供了一个数据平台，旨在帮助AI开发者管理非结构化数据，支持数据集的版本控制和可视化，并提供Python SDK方便集成。	作为一个综合性平台，其设计可能包含了较多功能，对于寻求一个轻量级、专注核心功能且易于私有化部署的团队而言，可能显得较为复杂。

此分析揭示了一个关键的技术差距：市场仍缺乏一个能直接解决版本控制混乱和工具链碎片化挑战的解决方案，该方案需将对象存储的扩展性、结构化元数据管理的灵活性、以及不可变的数据版本控制紧密集成。现有工具要么偏向于社区共享，要么与本地开发环境绑定过深，要么是功能全面的商业平台。因此，开发一个专注于内部DCAI工作流、易于部署和维护的核心数据管理系统，正是本项目旨在填补的技术空白。

在明确了现有工作的优势与不足之后，下一章节将详细阐述本项目针对这一市场空白所提出的系统设计方案。

3. 系统设计与功能需求 (System Design and Functional Requirements)

本系统的核心设计理念是借鉴现代数据栈的最佳实践，构建一个模块化、容器化且易于部署的架构。该架构旨在确保系统具备高度的可扩展性、灵活性和可维护性，以适应快速迭代的AI研发需求。

3.1 系统总体架构 (System Architecture)

系统将采用“湖仓一体”（Lakehouse）的混合架构。该架构旨在结合数据湖（Data Lake）处理多样化数据的灵活性与数据仓库（Data Warehouse）高性能的结构化管理能力，特别适合同时处理AI工作流中的非结构化文件和丰富的结构化元数据。

系统的核心技术选型如下：

* 对象存储层 (Object Storage Layer): 采用 MinIO 作为底层存储引擎。MinIO是一个高性能、与S3 API兼容的对象存储服务，负责持久化存储所有原始数据文件（如图片、文本、音频等）。我们将启用其内置的版本控制功能，以实现数据的不可变性和历史追溯。
* 元数据管理层 (Metadata Management Layer): 采用 PostgreSQL 关系型数据库。该数据库负责存储和管理与数据对象相关的所有结构化元数据，例如版本信息、标签、文件大小、创建时间、数据质量统计结果等，并支持高效的元数据查询。
* 应用服务层 (Application Service Layer): 采用 FastAPI Python框架构建RESTful API。该层是系统的核心业务逻辑处理中心，负责处理来自客户端的请求，协调MinIO和PostgreSQL的操作，并向外暴露统一、规范的接口。
* 容器化与编排 (Containerization & Orchestration): 采用 Docker Compose 将上述所有服务（MinIO, PostgreSQL, FastAPI）进行容器化封装和统一管理。这确保了开发、测试和生产环境的一致性，极大地简化了系统的部署和运维流程。

在一个典型的数据上传流程中，用户通过API将文件上传至应用服务层。服务层首先将文件持久化到MinIO的指定存储桶中，MinIO会返回一个唯一的对象versionID。随后，服务层将文件的元数据（如名称、路径、大小）连同此versionID作为外键，结构化地记录到PostgreSQL数据库中，从而完成一次原子性的数据入库操作。这一模块化、容器化的湖仓一体架构经过精心设计，旨在为版本控制、元数据管理和管道集成等核心DCAI工作流提供一个可扩展且稳固的基础，与我们的主要项目目标完全一致。

3.2 核心功能模块 (Core Functional Modules)

3.2.1 数据存储与版本控制 (Data Storage and Versioning)

本系统的数据版本控制机制深度依赖于MinIO和PostgreSQL的协同工作。系统将利用MinIO的对象版本控制功能，确保任何对文件的修改或删除操作都不会覆盖原始数据，而是创建一个新的对象版本。这种“不可变性”（Immutability）是实现实验可复现性的关键。

一个数据集“快照”（snapshot）并非数据的物理副本，而是在PostgreSQL中构建的元数据集合。它由一组命名的指针构成，每个指针将一个逻辑文件名映射到一个唯一的MinIO对象versionID。这使得用户可以随时检出（checkout）任意历史版本的数据集，从而确保了AI模型训练的可追溯性和结果的可复现性。

3.2.2 元数据管理 (Metadata Management)

丰富的元数据是实现数据发现、治理和高效利用的基础。本系统计划支持多种类型的元数据，以全面描述和管理数据集。

元数据类型 (Metadata Type)	目的 (Purpose)	示例属性 (Example Attributes)
描述性 (Descriptive)	用于数据的识别与发现	标题、标签、摘要、作者
结构性 (Structural)	描述数据的组织和关系	父数据集ID、序列号、文件类型
管理性 (Administrative)	用于数据的管理与控制	创建日期、访问权限、过期策略
技术性 (Technical)	描述文件的系统级细节	文件大小、MD5哈希值、图像分辨率

3.2.3 数据质量与可视化 (Data Quality and Visualization)

此模块是系统未来的重要扩展方向。我们计划在后端集成自动化的数据统计分析功能。例如，对于一个图像分类任务的数据集，系统可以自动计算并存储各个类别的样本数量分布。这些统计信息将作为元数据被记录，帮助用户快速评估数据是否存在类别不均衡等问题。

未来，系统还将开发一个前端可视化仪表盘，用于直观展示数据集的健康状况、统计分布和关键指标，从而辅助用户进行高效的数据探索和质量评估。更长远的目标是集成高级数据准备功能，例如提供**下采样工具（Downsampling Utilities）来平衡多数类，或集成合成数据生成（Synthetic Generation Integration）**接口以增强少数类。

3.2.4 API与SDK集成 (API and SDK Integration)

系统将通过FastAPI提供一组定义清晰、文档完备的RESTful API，以支持对数据集的程序化访问。这些API将覆盖数据上传、下载、元数据查询、版本管理等所有核心功能。

作为远期目标，我们将开发一个配套的Python SDK。该SDK将封装底层的API调用，使数据科学家能够通过一行简单的命令（例如 dms.get_data(dataset='imagenet', version='v1.2')）将特定版本的数据无缝加载到Pandas DataFrame或PyTorch/TensorFlow的数据加载器中，从而极大地简化训练流程。

上述设计旨在构建一个功能强大、架构清晰且易于扩展的数据管理系统，为后续的开发工作奠定坚实的基础。

4. 初步研究进展 (Preliminary Progress)

目前，本项目已处于开发的中后期阶段，核心的基础设施已经搭建完成并可稳定运行，初步的数据上传与查询流程也已得到验证。这为后续高级功能的开发奠定了坚实的基础。

当前已完成的主要工作包括：

1. 完成容器化部署: 已成功使用Docker Compose将FastAPI应用服务、PostgreSQL数据库和MinIO对象存储服务集成在同一个隔离的网络环境中，实现了开发环境的一键启动和部署。
2. 构建对象持久化层: 已成功配置并启动MinIO服务，创建了用于存储数据集的存储桶（bucket），并启用了版本控制功能。这为所有存储的数据提供了基础的数据保护和历史追溯能力。
3. 建立元数据数据库: 已设计并实现了初步的PostgreSQL数据库模式（schema），建立了用于存储数据集、文件对象及其版本信息的表结构，能够有效追踪对象键、大小、时间戳等基本元数据。
4. 实现基础API接口: 已基于FastAPI框架开发了初始的RESTful API端点，目前支持文件的上传操作以及数据集元数据列表的检索功能，验证了整个数据流的通畅性。

当前的进展表明，项目的核心架构设计是可行的，并且已经为下一阶段的功能开发和系统完善做好了充分准备。

5. 工作计划与进度安排 (Work Plan and Schedule)

为了确保毕业设计项目能够按时、高质量地完成，我们制定了详细的、分阶段的开发计划。每个阶段都设定了明确的里程碑和可衡量的交付成果。

里程碑 (Milestone)	主要交付成果 (Deliverable)	目标周 (Target Week)
M1: 统计模块 (Statistics Module)	完成后端统计模块的开发与测试。	第8周
M2: 可视化仪表盘 (Visualization Dashboard)	部署1.0版本的可视化仪表盘，用于数据健康状况监控。	第12周
M3: 数据提交功能 (Data Committing)	实现并验证不可变数据集快照的创建与管理功能。	第16周
M4: 训练集成 (Training Integration)	发布具备核心数据检索功能的初步版Python SDK。	第20周
M5: RBAC与安全性 (RBAC & Security)	完成基础的用户角色与身份验证层的设计与实现。	第24周
M6: 最终测试 (Final Testing)	完成系统性能基准测试报告并修复已识别的缺陷。	第28周
M7: 最终提交 (Final Submission)	完成毕业论文的最终撰写和项目演示准备。	第32周

本开题报告已全面阐述了项目的理论基础、技术方案、实施路径和预期成果。我们有信心按照既定计划稳步推进，并最终完成一个高质量的毕业设计项目。

6. 参考文献 (References)

[此部分将在最终论文撰写阶段，根据报告中所引用的Source Context内容进行格式化和填充。]
